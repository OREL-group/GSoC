{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Simulation Run for an Active Inference Model of Collective Intelligence",
      "provenance": [],
      "collapsed_sections": [
        "-qnFTF8bQXAm"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLexLpqIqFJf"
      },
      "source": [
        "# An Active Inference Model of Collective Intelligence\n",
        "#### By Rafael Kaufmann, Pranav Gupta, and Jacob Taylor\n",
        "Corresponding author: jacob.taylor@anthro.ox.ac.uk\n",
        "- Paper reporting results and the larger framework currently under review\n",
        "- The base model implements AIF in a simplified sensory environment as explained in [McGregor et al. 2015](https://arxiv.org/abs/1503.04187)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnWnI9xGhbnD"
      },
      "source": [
        "### Agent Code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWUhsg0dI7nI"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "pd.options.display.float_format = '{:20,.4f}'.format\n",
        "import seaborn as sns\n",
        "sns.set_style(\"whitegrid\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUA4wKuu1p0W"
      },
      "source": [
        "# Helper Functions\n",
        "\n",
        "def model_encoding(b):\n",
        "  \"\"\"\n",
        "  Probability of occupying specific position as encoded in the internal state.\n",
        "  \"\"\"\n",
        "  return softmax(b)\n",
        "\n",
        "def model_encoding_derivative(b):\n",
        "  \"\"\"\n",
        "  Derivative of the model encoding for free energy gradient calculation\n",
        "  \"\"\"\n",
        "  return D_softmax(model_encoding(b))\n",
        "\n",
        "def variational_density(b):\n",
        "  \"\"\"\n",
        "  P(psi | b)\n",
        "  Agent's belief about the external states (i.e. its current position in the \n",
        "  world) or intention (i.e. desired position in the world) as encoded in the\n",
        "  internal state.\n",
        "  \"\"\"\n",
        "  return model_encoding(b)\n",
        "\n",
        "def logdiff(p1, p2):\n",
        "  return (np.log(p1) - np.log(p2))\n",
        "\n",
        "def KLv(p1, p2):\n",
        "  return np.multiply(p1, logdiff(p1, p2))\n",
        "\n",
        "def KL(p1, p2):\n",
        "  \"\"\"\n",
        "  Kullback-Leibler divergence between densities 1 and 2.\n",
        "  \"\"\"\n",
        "  return np.sum(KLv(p1, p2))\n",
        "\n",
        "def softmax(b):\n",
        "  # Softmax function. The shift by b.max() is for numerical stability\n",
        "  sum = np.sum(np.exp(b - b.max()))\n",
        "  return np.exp(b - b.max()) / sum\n",
        "\n",
        "def D_softmax(q):\n",
        "  # Gradient of softmax function\n",
        "  return np.diag(q) - np.outer(q, q)\n",
        "\n",
        "def rerange(q, a):\n",
        "  return a * q + (1-a)/ENV_SIZE\n",
        "\n",
        "def dynamic_rerange(q):\n",
        "  B_MIN = -10\n",
        "  b = np.log(q)\n",
        "  b -= np.max(b)\n",
        "  b_hat = np.maximum(b, B_MIN)\n",
        "  return softmax(b_hat)\n",
        "\n",
        "def p_action(q):\n",
        "  # probability of partner action\n",
        "  p = []\n",
        "  q_hat = 0.9 * q / np.max(q)\n",
        "  p.append(q_hat)  # a_p = 0\n",
        "  A = (1-q_hat) / (np.roll(q, 1) + np.roll(q, -1))\n",
        "  p.append(np.roll(q, -1) * A)  # a_p = -1\n",
        "  p.append(np.roll(q, +1) * A)  # a_p = +1\n",
        "  return np.array(p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cn_4LCWV1sJs"
      },
      "source": [
        "# Agent Class: Core Mechanics of AIF with ToM and Alignment\n",
        "\n",
        "class Agent():\n",
        "  def __init__(self, psi, b_star, perceptiveness, alterity, alignment):\n",
        "    # intializations\n",
        "    self.psi = psi\n",
        "    self.alterity = alterity\n",
        "    env = np.array(range(ENV_SIZE))\n",
        "    self.sensory_dynamics = perceptiveness * np.exp(-SENSE_DECAY_RATE * \n",
        "                np.minimum(np.abs(env - int(ENV_SIZE/2)), np.abs(env - int(ENV_SIZE/2) - ENV_SIZE)))\n",
        "    self.b = (np.zeros(ENV_SIZE), np.zeros(ENV_SIZE))\n",
        "    self.b_star = (b_star[0] + (1 - alignment) * b_star[1],\n",
        "                   b_star[0] + (1 - alignment) * b_star[2])\n",
        "    self.q = (variational_density(self.b[0]), variational_density(self.b[1]))\n",
        "    self.q_star = (variational_density(self.b_star[0]), variational_density(self.b_star[1]))\n",
        "    self.p_ap = p_action(self.q_star[1])\n",
        "    self.a = (0,0)\n",
        "    self.a_pp = 0           \n",
        "    self.delta = 0\n",
        "    \n",
        "    # logs\n",
        "    self.psi_trace = [psi]\n",
        "    self.psi_partner_trace = []\n",
        "    self.b_own_trace = [self.sensory_dynamics]\n",
        "    self.b_partner_trace = [self.sensory_dynamics]\n",
        "    self.s_trace = []\n",
        "    self.a_trace = []\n",
        "\n",
        "  def free_energy_own(self, a, p_own, p_partner):\n",
        "    p_partner_reranged = rerange(p_partner, self.alterity)\n",
        "    p_partner_shifted = np.roll(p_partner_reranged, self.delta + a[0] - a[1])\n",
        "    return KL(self.q_star[0], dynamic_rerange(p_own * p_partner_shifted))\n",
        "\n",
        "  def free_energy_partner(self, a, p_own, p_partner):\n",
        "    p_own_reranged = rerange(p_own, self.alterity ** 2)\n",
        "    p_own_shifted = np.roll(p_own_reranged, - (self.delta + a[0] - a[1]))\n",
        "    return KL(self.q_star[1], dynamic_rerange(p_partner * p_own_shifted))\n",
        "\n",
        "  def fe_gradient(self, b_prime, p_own, p_partner, delta_prime):\n",
        "    \"\"\"\n",
        "    Partial derivatives of the free energy with respect to belief.\n",
        "    FE = KL(q_own || p_own * q_partner[-delta]) + KL(q_partner || p_partner * q_own[+delta])\n",
        "    \"\"\"\n",
        "    q_own = variational_density(b_prime[0])\n",
        "    q_partner = variational_density(b_prime[1])\n",
        "    p_own_reranged = rerange(p_own, self.alterity ** 2)\n",
        "    p_partner_reranged = rerange(p_partner, self.alterity)\n",
        "    p_own_shifted = np.roll(p_own_reranged, -delta_prime)\n",
        "    p_partner_shifted = np.roll(p_partner_reranged, delta_prime)\n",
        "\n",
        "    Dq_own = D_softmax(q_own)\n",
        "    Dq_partner = D_softmax(q_partner)\n",
        "\n",
        "    v = (1 + logdiff(q_own, dynamic_rerange(p_own * p_partner_shifted)),\n",
        "         1 + logdiff(q_partner, dynamic_rerange(p_partner * p_own_shifted)))\n",
        "    \n",
        "    return np.array([np.dot(Dq_own, v[0]), np.dot(Dq_partner, v[1])])\n",
        "\n",
        "  def generative_density_own(self, a=(0,0)):\n",
        "    q_own = self.q[0]\n",
        "    sd = self.sensory_dynamics if self.s == 1 else 1 - self.sensory_dynamics\n",
        "    return np.roll(sd * q_own, a[0])\n",
        "  \n",
        "  def generative_density_partner(self, a=(0,0)):\n",
        "    q_own = self.q[0]\n",
        "    q_partner = self.q[1]\n",
        "\n",
        "    p_delta = np.roll(q_own, -self.delta)\n",
        "    p_app = np.roll(self.p_ap[ACTIONS.index(self.a_pp)], -self.a_pp)\n",
        "    p_j_prior = q_partner\n",
        "    p_j_posterior = p_delta * p_app * p_j_prior\n",
        "    return np.roll(p_j_posterior, a[1])\n",
        "\n",
        "  def step(self):\n",
        "    # Role the dice on measuring sensory state s \\in {0, 1}\n",
        "    s = int(np.random.random() < self.sensory_dynamics[self.psi])\n",
        "    self.s = s\n",
        "\n",
        "    # Pick action state, a \\in {-1, 0, 1}^2 (pair of own and partner actions)\n",
        "    # Calculate the free energy given my target (intent) distribution, current state distribution, & sensory input \n",
        "    # Do this for all (three) actions and select the action with minimum free energy.\n",
        "    \n",
        "    fes = []\n",
        "    epsilon = 0.999 + np.random.random(3)*0.002  # perturb values to randomize the action chosen if equal FE \n",
        "    for a in ACTIONS_SQUARED:\n",
        "      p_own = self.generative_density_own(a)\n",
        "      p_partner = self.generative_density_partner(a)\n",
        "      fes.append([self.free_energy_own(a, p_own, p_partner) * epsilon[a[0]+1], \n",
        "                  self.free_energy_partner(a, p_own, p_partner)])\n",
        "    fes_t = np.transpose(fes)\n",
        "    actions_index = [np.argmin(fes_t[0]), np.argmin(fes_t[1])]\n",
        "    a = (ACTIONS_SQUARED[actions_index[0]][0], ACTIONS_SQUARED[actions_index[1]][1])\n",
        "    self.a = a\n",
        "    delta_prime = self.delta + a[0] - a[1]\n",
        "\n",
        "    # Update actual (own) position by taking action. Of course, partner action never gets realized\n",
        "    psi = (self.psi + a[0]) % ENV_SIZE\n",
        "    self.psi = psi\n",
        "\n",
        "    p_own = self.generative_density_own()\n",
        "    p_partner = self.generative_density_partner()\n",
        "    b_prime = np.array([np.roll(self.b[0], a[0]), np.roll(self.b[1], a[1])])\n",
        "    \n",
        "    # Now minimise free energy\n",
        "    for step in range(N_STEPS):\n",
        "      b_prime -= LEARNING_RATE * self.fe_gradient(b_prime, np.roll(p_own, a[0]), np.roll(p_partner, a[1]), delta_prime)\n",
        "\n",
        "    # Save position, sensory output, and internal state for plotting\n",
        "    self.b = b_prime\n",
        "    self.q = (variational_density(b_prime[0]), variational_density(b_prime[1]))\n",
        "    self.s_trace.append(s)\n",
        "    self.a_trace.append(a[0])\n",
        "    self.psi_trace.append(psi)\n",
        "    self.psi_partner_trace.append(psi - self.delta)\n",
        "    self.b_own_trace.append(model_encoding(b_prime[0]))\n",
        "    self.b_partner_trace.append(model_encoding(b_prime[1]))\n",
        "\n",
        "  def plot_traces(self):\n",
        "    \"\"\"\n",
        "    Helper function for plotting agent's internal state and position + agent's beliefs about partner's position.\n",
        "    \"\"\"\n",
        "    # Plot own belief trace\n",
        "    fig1 = plt.figure(figsize=(15, 4))\n",
        "    ax = fig1.gca()\n",
        "    im = ax.imshow(np.transpose(self.b_own_trace),\n",
        "              interpolation=\"nearest\", \n",
        "              aspect = \"auto\", \n",
        "              vmin = 0, vmax = 1, \n",
        "              cmap = \"viridis\")\n",
        "    c = np.asarray(['white' if s==1 else 'grey' for s in self.s_trace])\n",
        "    psi = np.asarray(self.psi_trace)\n",
        "    epochs = np.arange(EPOCHS+1)\n",
        "    self.a_trace.append(0)\n",
        "    a = np.asarray(self.a_trace)\n",
        "    idx = a<0\n",
        "    ax.scatter(epochs[idx], psi[idx], c = c[idx], marker = 'v')\n",
        "    idx = a>0\n",
        "    ax.scatter(epochs[idx], psi[idx], c = c[idx], marker = '^')\n",
        "    idx = a==0\n",
        "    ax.scatter(epochs[idx], psi[idx], c = c[idx], marker = 'o')    \n",
        "    ax.invert_yaxis()\n",
        "    ax.set_xlim([0,EPOCHS+1])\n",
        "    fig1.colorbar(im)\n",
        "\n",
        "    # Then plot partner belief trace\n",
        "    fig2 = plt.figure(figsize=(15, 4))\n",
        "    ax = fig2.gca()\n",
        "    im = ax.imshow(np.transpose(self.b_partner_trace),\n",
        "              interpolation=\"nearest\", \n",
        "              aspect = \"auto\", \n",
        "              vmin = 0, vmax = 1, \n",
        "              cmap = \"viridis\")   \n",
        "    ax.invert_yaxis()\n",
        "    ax.set_xlim([0,EPOCHS+1])\n",
        "    fig2.colorbar(im)\n",
        "\n",
        "    return fig1, fig2\n",
        "\n",
        "  def log_convergence(self, targets):\n",
        "    \"\"\"\n",
        "    Helper function to calculate absolute distance from target position.\n",
        "    \"\"\"\n",
        "    psi = np.array(self.psi_trace)\n",
        "    c0 = np.minimum(np.abs(psi - targets[0]), \n",
        "                    np.minimum(np.abs(psi - targets[0] - ENV_SIZE),\n",
        "                               np.abs(psi - targets[0] + ENV_SIZE)))\n",
        "    if len(targets) == 1:\n",
        "      return 'shared target', c0\n",
        "    \n",
        "    c1 = np.minimum(np.abs(psi - targets[1]), \n",
        "                    np.minimum(np.abs(psi - targets[1] - ENV_SIZE), \n",
        "                               np.abs(psi - targets[1] + ENV_SIZE)))\n",
        "    # return the convergent distance from closest target.\n",
        "    if c0[-1] <= c1[-1]:\n",
        "      return 'shared target', c0\n",
        "    else:\n",
        "      return 'unshared target', c1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXVOVccb18J2"
      },
      "source": [
        "# Simulation Functions\n",
        "\n",
        "def simulate_agents(ag):\n",
        "  \"\"\"\n",
        "  Simulate the agents for EPOCHS steps.\n",
        "  \"\"\"\n",
        "  for epoch in range(EPOCHS):\n",
        "    # Update each agent's perceived delta with their actual delta\n",
        "    delta = [0, 0]\n",
        "    delta[0] = ag[0].psi - ag[1].psi\n",
        "    delta[1] = -delta[0]\n",
        "    ag[0].delta = delta[0]\n",
        "    ag[1].delta = delta[1]\n",
        "\n",
        "    # Update each agent's perceived partner action with their partner's previous action\n",
        "    ag[0].a_pp = ag[1].a[0]\n",
        "    ag[1].a_pp = ag[0].a[0]\n",
        "\n",
        "    for i in range(2):\n",
        "      ag[i].step()\n",
        "\n",
        "  # For plotting add target position as probability distribution at the end of the belief trace\n",
        "  for i in range(2):\n",
        "    tgt = model_encoding(ag[i].b_star[0])\n",
        "    ag[i].b_own_trace.append(tgt/tgt.max())\n",
        "    ag[i].s_trace.append(int(np.random.random() < ag[i].sensory_dynamics[ag[i].psi]))\n",
        "  return ag\n",
        "\n",
        "def initialize_b_star(targets, sharpness=6):\n",
        "  b_star = []\n",
        "  B_STANDARD = np.array([np.exp(-((i-ENV_SIZE/2)/(ENV_SIZE/sharpness))**2) for i in range(ENV_SIZE)])\n",
        "  for target in targets:\n",
        "    b_star.append(np.roll(B_STANDARD, target-ENV_SIZE // 2))\n",
        "  return b_star\n",
        "\n",
        "def singleRun(shared_target, perceptiveness, alterity, alignment, plot=False):\n",
        "\n",
        "  # initialize agents\n",
        "  initial_positions = [(shared_target + SHORTEST_PATH) % ENV_SIZE,\n",
        "                       (shared_target - SHORTEST_PATH) % ENV_SIZE]\n",
        "\n",
        "  target_0 = (shared_target - TARGET_DELTA) % ENV_SIZE\n",
        "  target_1 = (shared_target + TARGET_DELTA) % ENV_SIZE\n",
        "  \n",
        "  b_star_0 = initialize_b_star([shared_target, target_0, target_1])\n",
        "  b_star_1 = initialize_b_star([shared_target, target_1, target_0])\n",
        "\n",
        "  # Run simulation\n",
        "  agents = (Agent(initial_positions[0], b_star_0,\n",
        "                  perceptiveness[0], alterity[0], alignment),\n",
        "            Agent(initial_positions[1], b_star_1,\n",
        "                  perceptiveness[1], alterity[1], alignment))\n",
        "  agents = simulate_agents(agents)\n",
        "\n",
        "  # Plot output\n",
        "  if plot:\n",
        "    for i in range(2):\n",
        "      agents[i].plot_traces()\n",
        "    \n",
        "  tgt_0, log_0 = agents[0].log_convergence([shared_target, target_0])\n",
        "  tgt_1, log_1 = agents[1].log_convergence([shared_target, target_1])\n",
        "\n",
        "  b_end_0 = np.roll(agents[0].b_own_trace[-2], (int(ENV_SIZE/2) - shared_target) % ENV_SIZE)\n",
        "  b_end_1 = np.roll(agents[1].b_own_trace[-2], (int(ENV_SIZE/2) - shared_target) % ENV_SIZE)\n",
        "\n",
        "  return tgt_0, log_0, b_end_0, agents[0].psi_trace, tgt_1, log_1, b_end_1, agents[1].psi_trace\n",
        "\n",
        "def simulateRuns(model=1, no_of_cycles=1):\n",
        "\n",
        "  alterity = CONDITIONS[model]['tom']\n",
        "  alignment = CONDITIONS[model]['alignment']\n",
        "\n",
        "  # multiple runs\n",
        "  dft1 = pd.DataFrame()\n",
        "  dft2 = pd.DataFrame()\n",
        "  dfc1 = pd.DataFrame()\n",
        "  dfc2 = pd.DataFrame()\n",
        "  dfb1 = pd.DataFrame()\n",
        "  dfb2 = pd.DataFrame()\n",
        "  q_empirical = np.zeros([EPOCHS, ENV_SIZE])\n",
        "\n",
        "  print('Running model: ' + str(model))\n",
        "  print(' > Env Size: ' + str(ENV_SIZE))\n",
        "  print(' > Perceptiveness: ' + str(MAX_SENSE_PROBABILITY))\n",
        "  print(' > ToM: ' + str(alterity))\n",
        "  print(' > Alignment: ' + str(alignment))\n",
        "\n",
        "  print('Starting Simulation Runs: ' + str(no_of_cycles * ENV_SIZE))\n",
        "  print(\" > Start Time =\", datetime.now().strftime(\"%H:%M:%S\"))\n",
        "\n",
        "  for i in range(no_of_cycles):\n",
        "    for shared_target in range(ENV_SIZE):\n",
        "      if (shared_target % 10 == 0): \n",
        "        print(\"   run: \" + str(i * ENV_SIZE + shared_target)) \n",
        "      \n",
        "      t1, c1, b1, psi1, t2, c2, b2, psi2 = singleRun(shared_target, MAX_SENSE_PROBABILITY, alterity, alignment)\n",
        "      \n",
        "      dft1 = dft1.append(pd.Series(t1), ignore_index=True)\n",
        "      dft2 = dft2.append(pd.Series(t2), ignore_index=True)\n",
        "      dfc1 = dfc1.append(pd.Series(c1), ignore_index=True)\n",
        "      dfc2 = dfc2.append(pd.Series(c2), ignore_index=True)\n",
        "      dfb1 = dfb1.append(pd.Series(b1).T, ignore_index=True)\n",
        "      dfb2 = dfb2.append(pd.Series(b2).T, ignore_index=True)\n",
        "      for t in range(EPOCHS):  ## ?? decribe metric\n",
        "        q_empirical[t, psi1[t] - shared_target] += 1\n",
        "        q_empirical[t, psi2[t] - shared_target] += 1\n",
        "\n",
        "  print(\" > End Time =\", datetime.now().strftime(\"%H:%M:%S\"))\n",
        "  print('Simulation Complete for Model: ' + str(model))\n",
        "\n",
        "  # generate results data\n",
        "  t_composite = targetData(dft1, dft2)\n",
        "  c_composite = convergenceData(dfc1, dfc2)\n",
        "  b_composite = beliefData(dfb1, dfb2)\n",
        "  fedf = systemFreeEnergyData(q_empirical)\n",
        "\n",
        "  return model, t_composite, c_composite, b_composite, fedf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEJSL8Xj0Ey_"
      },
      "source": [
        "# Functions for capturing run data\n",
        "\n",
        "def targetData(dft1, dft2):\n",
        "  # collate target data and calculate % time agents pursue primary/secondary target\n",
        "  dft1.columns = ['Target']\n",
        "  dft1['Agent'] = 'strong'\n",
        "  dft2.columns = ['Target']\n",
        "  dft2['Agent'] = 'weak'\n",
        "  return pd.concat([dft1, dft2], ignore_index=True)\n",
        "\n",
        "def convergenceData(dfc1, dfc2):\n",
        "  # collate and plot convergence to target\n",
        "  dfc1 = dfc1.melt()\n",
        "  dfc1.columns = [\"Time\", \"Distance from Target\"]\n",
        "  dfc1['Agent'] = 'strong'\n",
        "\n",
        "  dfc2 = dfc2.melt()\n",
        "  dfc2.columns = [\"Time\", \"Distance from Target\"]\n",
        "  dfc2['Agent'] = 'weak'\n",
        "\n",
        "  return pd.concat([dfc1, dfc2], ignore_index=True)\n",
        "\n",
        "def beliefData(dfb1, dfb2):\n",
        "  # collate and plot final belief distribution (primary target fixed at the middle of the env.)\n",
        "  dfb1 = dfb1.melt()\n",
        "  dfb1.columns = [\"Relative Location\", \"Belief\"]\n",
        "  dfb1['Agent'] = 'strong'\n",
        "\n",
        "  dfb2 = dfb2.melt()\n",
        "  dfb2.columns = [\"Relative Location\", \"Belief\"]\n",
        "  dfb2['Agent'] = 'weak'\n",
        "\n",
        "  return pd.concat([dfb1, dfb2], ignore_index=True)\n",
        "\n",
        "def systemFreeEnergyData(q_empirical):\n",
        "  # Collate and plot FE based on distribution across all runs\n",
        "  global_p = initialize_b_star([0], 30)\n",
        "  global_p = global_p / np.sum(global_p)\n",
        "  fe = np.zeros(EPOCHS)\n",
        "\n",
        "  for t in range(EPOCHS):\n",
        "    q = (q_empirical[t] + 0.01) / (np.sum(q_empirical[t]) + 0.01 * ENV_SIZE)\n",
        "    fe[t] = KL(q, global_p)\n",
        "\n",
        "  return pd.DataFrame(fe, columns=['FE'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdPQsqsBstvS"
      },
      "source": [
        "### Run Simulations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJX1OZdi2DW-"
      },
      "source": [
        "# Declarations\n",
        "\n",
        "# Environmental Constants\n",
        "ENV_SIZE = 60                            # note: pick a number divisible by 6\n",
        "SHORTEST_PATH = int(ENV_SIZE / 3)        # distance of shared target from agent's initial position\n",
        "TARGET_DELTA = int(ENV_SIZE / 3)         # distance unshared target from shared target\n",
        "\n",
        "# Agent Constants\n",
        "ACTIONS = (0, -1, 1)                     # possible space of actions (stay, left, right)\n",
        "ACTIONS_SQUARED = ((0,0),(0,-1),(0,1),   # possible combined action space for 2 agents\n",
        "                   (-1,0),(-1,-1),(-1,1),\n",
        "                   (1,0),(1,-1),(1,1))\n",
        "MAX_SENSE_PROBABILITY = [0.99, 0.05]     # (strong, weak) agents\n",
        "SENSE_DECAY_RATE = np.log(4)/ENV_SIZE    # omega (ensures p=0.5 at ENV/2)\n",
        "\n",
        "# Simulation parameters\n",
        "EPOCHS = 200                 # Number of epochs (simulation steps).\n",
        "N_STEPS = 50                 # Number of gradient descent steps made to update beliefs in each epoch.\n",
        "LEARNING_RATE = 0.7          # Stochastic gradient descent learning rate\n",
        "\n",
        "# Experimental parameters \n",
        "# ALTERITY parameter for level of ToM (0, 1)\n",
        "# ALIGNMENT parameter for goal alignment (0, 1)\n",
        "CONDITIONS = {1: { 'model': 1, 'tom': [0, 0], 'alignment': 0},\n",
        "              2: { 'model': 2, 'tom': [0, 0.5], 'alignment': 0},\n",
        "              3: { 'model': 3, 'tom': [0, 0], 'alignment': 1},\n",
        "              4: { 'model': 4, 'tom': [0, 0.5], 'alignment': 1}}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUXtjIdY2RQv"
      },
      "source": [
        "# # single run\n",
        "# MODEL = 4   # <= specify model you want to run\n",
        "# FOOD_POSITION = 15\n",
        "# print(FOOD_POSITION)\n",
        "# t1, c1, b1, psi1, t2, c2, b2, psi2 = singleRun(FOOD_POSITION, \n",
        "#                                                MAX_SENSE_PROBABILITY,\n",
        "#                                                CONDITIONS[MODEL]['tom'], \n",
        "#                                                CONDITIONS[MODEL]['alignment'], plot=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niBB0utmSgu8",
        "outputId": "aad8187f-0510-4cff-9662-8bd308c8247c"
      },
      "source": [
        "# Run All Experimental Conditions\n",
        "for i in range(1, 5):\n",
        "  model, t_composite, c_composite, b_composite, fedf = simulateRuns(model = i, no_of_cycles = 3)\n",
        "  # writing results requires mounting gDrive (function below)\n",
        "  writeResults('AIF_60_Results', model, t_composite, c_composite, b_composite, fedf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running model: 1\n",
            " > Env Size: 60\n",
            " > Perceptiveness: [0.99, 0.05]\n",
            " > ToM: [0, 0]\n",
            " > Alignment: 0\n",
            "Starting Simulation Runs: 180\n",
            " > Start Time = 23:18:25\n",
            "   run: 0\n",
            "   run: 10\n",
            "   run: 20\n",
            "   run: 30\n",
            "   run: 40\n",
            "   run: 50\n",
            "   run: 60\n",
            "   run: 70\n",
            "   run: 80\n",
            "   run: 90\n",
            "   run: 100\n",
            "   run: 110\n",
            "   run: 120\n",
            "   run: 130\n",
            "   run: 140\n",
            "   run: 150\n",
            "   run: 160\n",
            "   run: 170\n",
            " > End Time = 23:38:28\n",
            "Simulation Complete for Model: 1\n",
            "   Writing GSheet: AIF_60_Results > M1_Targets ...\n",
            "   Writing GSheet: AIF_60_Results > M1_Convergence ...\n",
            "   Writing GSheet: AIF_60_Results > M1_Belief ...\n",
            "   Writing GSheet: AIF_60_Results > M1_FE ...\n",
            "Running model: 2\n",
            " > Env Size: 60\n",
            " > Perceptiveness: [0.99, 0.05]\n",
            " > ToM: [0, 0.2]\n",
            " > Alignment: 0\n",
            "Starting Simulation Runs: 180\n",
            " > Start Time = 23:45:55\n",
            "   run: 0\n",
            "   run: 10\n",
            "   run: 20\n",
            "   run: 30\n",
            "   run: 40\n",
            "   run: 50\n",
            "   run: 60\n",
            "   run: 70\n",
            "   run: 80\n",
            "   run: 90\n",
            "   run: 100\n",
            "   run: 110\n",
            "   run: 120\n",
            "   run: 130\n",
            "   run: 140\n",
            "   run: 150\n",
            "   run: 160\n",
            "   run: 170\n",
            " > End Time = 00:05:54\n",
            "Simulation Complete for Model: 2\n",
            "   Writing GSheet: AIF_60_Results > M2_Targets ...\n",
            "   Writing GSheet: AIF_60_Results > M2_Convergence ...\n",
            "   Writing GSheet: AIF_60_Results > M2_Belief ...\n",
            "   Writing GSheet: AIF_60_Results > M2_FE ...\n",
            "Running model: 3\n",
            " > Env Size: 60\n",
            " > Perceptiveness: [0.99, 0.05]\n",
            " > ToM: [0, 0]\n",
            " > Alignment: 1\n",
            "Starting Simulation Runs: 180\n",
            " > Start Time = 00:06:14\n",
            "   run: 0\n",
            "   run: 10\n",
            "   run: 20\n",
            "   run: 30\n",
            "   run: 40\n",
            "   run: 50\n",
            "   run: 60\n",
            "   run: 70\n",
            "   run: 80\n",
            "   run: 90\n",
            "   run: 100\n",
            "   run: 110\n",
            "   run: 120\n",
            "   run: 130\n",
            "   run: 140\n",
            "   run: 150\n",
            "   run: 160\n",
            "   run: 170\n",
            " > End Time = 00:26:13\n",
            "Simulation Complete for Model: 3\n",
            "   Writing GSheet: AIF_60_Results > M3_Targets ...\n",
            "   Writing GSheet: AIF_60_Results > M3_Convergence ...\n",
            "   Writing GSheet: AIF_60_Results > M3_Belief ...\n",
            "   Writing GSheet: AIF_60_Results > M3_FE ...\n",
            "Running model: 4\n",
            " > Env Size: 60\n",
            " > Perceptiveness: [0.99, 0.05]\n",
            " > ToM: [0, 0.2]\n",
            " > Alignment: 1\n",
            "Starting Simulation Runs: 180\n",
            " > Start Time = 00:26:32\n",
            "   run: 0\n",
            "   run: 10\n",
            "   run: 20\n",
            "   run: 30\n",
            "   run: 40\n",
            "   run: 50\n",
            "   run: 60\n",
            "   run: 70\n",
            "   run: 80\n",
            "   run: 90\n",
            "   run: 100\n",
            "   run: 110\n",
            "   run: 120\n",
            "   run: 130\n",
            "   run: 140\n",
            "   run: 150\n",
            "   run: 160\n",
            "   run: 170\n",
            " > End Time = 00:46:28\n",
            "Simulation Complete for Model: 4\n",
            "   Writing GSheet: AIF_60_Results > M4_Targets ...\n",
            "   Writing GSheet: AIF_60_Results > M4_Convergence ...\n",
            "   Writing GSheet: AIF_60_Results > M4_Belief ...\n",
            "   Writing GSheet: AIF_60_Results > M4_FE ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIHBdWGszI7K"
      },
      "source": [
        "### Save data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kemiYlazPtU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e94c79f6-4562-4e89-bc3c-bd102b242589"
      },
      "source": [
        "# load gsheet library for reading and writing sim results\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import sys\n",
        "path_to_my_drive_folder = \"/content/drive/MyDrive/Colab Notebooks\" \n",
        "sys.path.append(path_to_my_drive_folder)\n",
        "import gsheet_lib as gs\n",
        "\n",
        "# write to gsheets\n",
        "def writeResults(results_sheet, model, t_composite, c_composite, b_composite, fedf):\n",
        "  \n",
        "  Mx = 'M' + str(model)\n",
        "  tabs = [Mx + '_Targets', Mx + '_Convergence', Mx + '_Belief', Mx + '_FE']\n",
        "\n",
        "  t_composite.index.name = 'ID'\n",
        "  gs.writeDfToGSheetTab(results_sheet, tabs[0], t_composite)\n",
        "\n",
        "  c_composite.index.name = 'ID'\n",
        "  gs.writeDfToGSheetTab(results_sheet, tabs[1], c_composite)\n",
        "\n",
        "  b_composite.index.name = 'ID'\n",
        "  gs.writeDfToGSheetTab(results_sheet, tabs[2], b_composite)\n",
        "\n",
        "  fedf.index.name = 'Time'\n",
        "  gs.writeDfToGSheetTab(results_sheet, tabs[3], fedf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIvwMQX4UHSK"
      },
      "source": [
        "### Plot from GSheet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLhygycWUM2e"
      },
      "source": [
        "plot_for_model = 1 # <= Enter model number for plotting here\n",
        "results_sheet = 'AIF_60_Results'\n",
        "Mx = 'M' + str(plot_for_model)\n",
        "tabs = [Mx + '_Targets', Mx + '_Convergence', Mx + '_Belief', Mx + '_FE']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2h_Of2m-3dao"
      },
      "source": [
        "t = gs.readDfFromGSheetTab(results_sheet, tabs[0]).set_index('ID')\n",
        "t = t.apply(pd.to_numeric, errors='ignore')\n",
        "t.groupby('Agent')['Target'].value_counts(normalize=True).mul(100).round(1).astype(str) + '%'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbJuo0D722co"
      },
      "source": [
        "c = gs.readDfFromGSheetTab(results_sheet, tabs[1]).set_index('ID')\n",
        "c = c.apply(pd.to_numeric, errors='ignore')\n",
        "g = sns.lineplot(data=c, x=\"Time\", y=\"Distance from Target\", hue='Agent', linewidth=2)\n",
        "g.set_xlim(0,EPOCHS)\n",
        "g.set_ylim(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZczavIDm22UT"
      },
      "source": [
        "b = gs.readDfFromGSheetTab(results_sheet, tabs[2]).set_index('ID')\n",
        "b = b.apply(pd.to_numeric, errors='ignore')\n",
        "g = sns.lineplot(data=b, x=\"Relative Location\", y=\"Belief\", hue='Agent', linewidth=2)\n",
        "g.set_xlim(0, ENV_SIZE-1)\n",
        "g.set_ylim(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qnFTF8bQXAm"
      },
      "source": [
        "### Scratch Pad\n",
        "- Alternative for specifying goal alignment parameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOP1v33vQVxs"
      },
      "source": [
        "shared_target = 30\n",
        "\n",
        "target_0 = (shared_target - TARGET_DELTA) % ENV_SIZE\n",
        "target_1 = (shared_target + TARGET_DELTA) % ENV_SIZE\n",
        "\n",
        "b_star_0 = initialize_b_star([shared_target, target_0, target_1], 10)\n",
        "b_star_1 = initialize_b_star([shared_target, target_1, target_0], 10)\n",
        "\n",
        "ALIGNMENT = 1\n",
        "\n",
        "# # parametrized logic (general version -- will need updating based on .append/+= in initialize b*)\n",
        "# B_STARS_ = (B_STARS[0] + ALIGNMENT * (np.minimum(B_STARS[0], B_STARS[1]) - B_STARS[0]),\n",
        "#             B_STARS[1] + ALIGNMENT * (np.minimum(B_STARS[0], B_STARS[1]) - B_STARS[1]))\n",
        "\n",
        "# newer bool logic (works only with explicit shared targets)\n",
        "B_STARS_NEW = (b_star_0[0] + (1 - ALIGNMENT) * b_star_0[1],\n",
        "               b_star_0[0] + (1 - ALIGNMENT) * b_star_0[2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "Xpg7f8E_AP0a",
        "outputId": "704d4642-714e-4919-bf4d-c215965027bf"
      },
      "source": [
        "sns.lineplot(x=range(0, ENV_SIZE), y=model_encoding(B_STARS_NEW[0]))  # initialized b* without alignment modification"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f13493e0590>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_U60GTgAiKp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}