{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary Design with Langchain and Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.2.4-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain_community)\n",
      "  Using cached PyYAML-6.0.1-cp311-cp311-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain_community)\n",
      "  Using cached SQLAlchemy-2.0.30-cp311-cp311-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain_community)\n",
      "  Using cached aiohttp-3.9.5-cp311-cp311-win_amd64.whl.metadata (7.7 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Using cached dataclasses_json-0.6.6-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting langchain<0.3.0,>=0.2.0 (from langchain_community)\n",
      "  Downloading langchain-0.2.3-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting langchain-core<0.3.0,>=0.2.0 (from langchain_community)\n",
      "  Downloading langchain_core-0.2.5-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.0 (from langchain_community)\n",
      "  Downloading langsmith-0.1.75-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting numpy<2,>=1 (from langchain_community)\n",
      "  Using cached numpy-1.26.4-cp311-cp311-win_amd64.whl.metadata (61 kB)\n",
      "Collecting requests<3,>=2 (from langchain_community)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tenacity<9.0.0,>=8.1.0 (from langchain_community)\n",
      "  Using cached tenacity-8.3.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Using cached attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Using cached frozenlist-1.4.1-cp311-cp311-win_amd64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Using cached multidict-6.0.5-cp311-cp311-win_amd64.whl.metadata (4.3 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Using cached yarl-1.9.4-cp311-cp311-win_amd64.whl.metadata (32 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading marshmallow-3.21.3-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain<0.3.0,>=0.2.0->langchain_community)\n",
      "  Downloading langchain_text_splitters-0.2.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting pydantic<3,>=1 (from langchain<0.3.0,>=0.2.0->langchain_community)\n",
      "  Downloading pydantic-2.7.3-py3-none-any.whl.metadata (108 kB)\n",
      "     ---------------------------------------- 0.0/109.0 kB ? eta -:--:--\n",
      "     --------------------- ----------------- 61.4/109.0 kB 1.7 MB/s eta 0:00:01\n",
      "     -------------------------------------- 109.0/109.0 kB 2.1 MB/s eta 0:00:00\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.0->langchain_community)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting packaging<24.0,>=23.2 (from langchain-core<0.3.0,>=0.2.0->langchain_community)\n",
      "  Using cached packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.0->langchain_community)\n",
      "  Using cached orjson-3.10.3-cp311-none-win_amd64.whl.metadata (50 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2->langchain_community)\n",
      "  Using cached charset_normalizer-3.3.2-cp311-cp311-win_amd64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2->langchain_community)\n",
      "  Using cached idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langchain_community)\n",
      "  Using cached urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2->langchain_community)\n",
      "  Downloading certifi-2024.6.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting typing-extensions>=4.6.0 (from SQLAlchemy<3,>=1.4->langchain_community)\n",
      "  Downloading typing_extensions-4.12.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain_community)\n",
      "  Using cached greenlet-3.0.3-cp311-cp311-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain_community)\n",
      "  Using cached jsonpointer-2.4-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain_community)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.18.4 (from pydantic<3,>=1->langchain<0.3.0,>=0.2.0->langchain_community)\n",
      "  Downloading pydantic_core-2.18.4-cp311-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Downloading langchain_community-0.2.4-py3-none-any.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/2.2 MB 7.0 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.8/2.2 MB 9.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.3/2.2 MB 9.1 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.5/2.2 MB 8.9 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.7/2.2 MB 7.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 8.1 MB/s eta 0:00:00\n",
      "Using cached aiohttp-3.9.5-cp311-cp311-win_amd64.whl (370 kB)\n",
      "Using cached dataclasses_json-0.6.6-py3-none-any.whl (28 kB)\n",
      "Downloading langchain-0.2.3-py3-none-any.whl (974 kB)\n",
      "   ---------------------------------------- 0.0/974.0 kB ? eta -:--:--\n",
      "   ------------------- ------------------- 491.5/974.0 kB 15.0 MB/s eta 0:00:01\n",
      "   --------------------------------------  972.8/974.0 kB 12.2 MB/s eta 0:00:01\n",
      "   --------------------------------------- 974.0/974.0 kB 10.3 MB/s eta 0:00:00\n",
      "Downloading langchain_core-0.2.5-py3-none-any.whl (314 kB)\n",
      "   ---------------------------------------- 0.0/314.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 314.7/314.7 kB 9.8 MB/s eta 0:00:00\n",
      "Downloading langsmith-0.1.75-py3-none-any.whl (124 kB)\n",
      "   ---------------------------------------- 0.0/124.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 124.9/124.9 kB 3.7 MB/s eta 0:00:00\n",
      "Using cached numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "Using cached PyYAML-6.0.1-cp311-cp311-win_amd64.whl (144 kB)\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "   ---------------------------------------- 0.0/64.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 64.9/64.9 kB ? eta 0:00:00\n",
      "Using cached SQLAlchemy-2.0.30-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "Using cached tenacity-8.3.0-py3-none-any.whl (25 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "Downloading certifi-2024.6.2-py3-none-any.whl (164 kB)\n",
      "   ---------------------------------------- 0.0/164.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 164.4/164.4 kB 10.3 MB/s eta 0:00:00\n",
      "Using cached charset_normalizer-3.3.2-cp311-cp311-win_amd64.whl (99 kB)\n",
      "Using cached frozenlist-1.4.1-cp311-cp311-win_amd64.whl (50 kB)\n",
      "Using cached greenlet-3.0.3-cp311-cp311-win_amd64.whl (292 kB)\n",
      "Using cached idna-3.7-py3-none-any.whl (66 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_text_splitters-0.2.1-py3-none-any.whl (23 kB)\n",
      "Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
      "   ---------------------------------------- 0.0/49.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 49.2/49.2 kB 2.4 MB/s eta 0:00:00\n",
      "Using cached multidict-6.0.5-cp311-cp311-win_amd64.whl (28 kB)\n",
      "Using cached orjson-3.10.3-cp311-none-win_amd64.whl (138 kB)\n",
      "Using cached packaging-23.2-py3-none-any.whl (53 kB)\n",
      "Downloading pydantic-2.7.3-py3-none-any.whl (409 kB)\n",
      "   ---------------------------------------- 0.0/409.6 kB ? eta -:--:--\n",
      "   ------------------------------------- - 389.1/409.6 kB 12.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 409.6/409.6 kB 6.3 MB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.18.4-cp311-none-win_amd64.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 0.5/1.9 MB 10.5 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.0/1.9 MB 12.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.5/1.9 MB 11.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.9/1.9 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 11.1 MB/s eta 0:00:00\n",
      "Downloading typing_extensions-4.12.1-py3-none-any.whl (37 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "Using cached yarl-1.9.4-cp311-cp311-win_amd64.whl (76 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
      "Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: urllib3, typing-extensions, tenacity, PyYAML, packaging, orjson, numpy, mypy-extensions, multidict, jsonpointer, idna, greenlet, frozenlist, charset-normalizer, certifi, attrs, annotated-types, yarl, typing-inspect, SQLAlchemy, requests, pydantic-core, marshmallow, jsonpatch, aiosignal, pydantic, dataclasses-json, aiohttp, langsmith, langchain-core, langchain-text-splitters, langchain, langchain_community\n",
      "Successfully installed PyYAML-6.0.1 SQLAlchemy-2.0.30 aiohttp-3.9.5 aiosignal-1.3.1 annotated-types-0.7.0 attrs-23.2.0 certifi-2024.6.2 charset-normalizer-3.3.2 dataclasses-json-0.6.6 frozenlist-1.4.1 greenlet-3.0.3 idna-3.7 jsonpatch-1.33 jsonpointer-2.4 langchain-0.2.3 langchain-core-0.2.5 langchain-text-splitters-0.2.1 langchain_community-0.2.4 langsmith-0.1.75 marshmallow-3.21.3 multidict-6.0.5 mypy-extensions-1.0.0 numpy-1.26.4 orjson-3.10.3 packaging-23.2 pydantic-2.7.3 pydantic-core-2.18.4 requests-2.32.3 tenacity-8.3.0 typing-extensions-4.12.1 typing-inspect-0.9.0 urllib3-2.2.1 yarl-1.9.4\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing out the local models\n",
    "1. Llama3 - 8b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Here's one:\\n\\nWhy don't scientists trust atoms?\\n\\nBecause they make up everything!\\n\\nHope that made you smile! Do you want to hear another?\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = Ollama(model=\"llama3:8b\")\n",
    "llm.invoke(\"Tell me a joke\",stop=['<|eot_id|>'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Mistralv2 - 7b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Why don't scientists trust atoms?\\n\\nBecause they make up everything!\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "llm = Ollama(model=\"mistral:v0.2\")\n",
    "llm.invoke(\"Tell me a joke\",stop=['<|eot_id|>'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing model's capabilities for the preliminary design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements :\n",
    "\n",
    "1. Code Ability\n",
    "2. Code Review\n",
    "3. Context understanding\n",
    "4. Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Code Ability \n",
    "    - without access to internet resources\n",
    "\n",
    "In our environment, to create a \"Contributor\" Agent, there will be multiple actions that the agent must do such as summarize the github issue, call the write_code method for different functions, and write tests for the code written, before merging and submitting for review. Here I demonstrate from them, summarizing a github issue, planning out the approach, calling the write code function for each and summaring the ans in a pull request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class CodingAgent:\n",
    "\n",
    "    def __init__(self, model_name):\n",
    "        self.role = \"\"\" You are a senior developer who writes efficient and neat code for problems\n",
    "         and can teach a junior developer how to code. Your language of choice is Python. Don't explain\n",
    "         the code, just generate the code block itself. \"\"\"\n",
    "        self.llm = Ollama(model=model_name)\n",
    "        self.context_history = {}\n",
    "        \n",
    "        \n",
    "    def reset(self):\n",
    "        self.context_history = {}\n",
    "    \n",
    "    def _parse_code(self, ans):\n",
    "        pattern = r\"```python(.*)```\"\n",
    "        match = re.search(pattern, ans, re.DOTALL)\n",
    "        code_text = match.group(1) if match else ans\n",
    "        return code_text\n",
    "    \n",
    "    def write_code(self, instruction):\n",
    "        self.prompt= f\"\"\" Write a python function that can {instruction}.\n",
    "    Return ```python your_code_here ``` with NO other texts,\n",
    "    your code:\n",
    "    \"\"\"\n",
    "        ans = self.llm.invoke(self.prompt,stop=['<|eot_id|>'])\n",
    "        code_text = self._parse_code(ans)\n",
    "\n",
    "        return code_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output from the Llama3 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "import requests\n",
      "import json\n",
      "\n",
      "class WeatherChecker:\n",
      "    def __init__(self, api_key):\n",
      "        self.api_key = api_key\n",
      "\n",
      "    def get_weather(self, city):\n",
      "        url = f\"http://api.openweathermap.org/data/2.5/weather?q={city}&appid={self.api_key}\"\n",
      "        response = requests.get(url)\n",
      "        return json.loads(response.text)\n",
      "\n",
      "    def print_weather(self, weather_data):\n",
      "        print(f\"Weather in {weather_data['name']}:\")\n",
      "        print(f\"Description: {weather_data['weather'][0]['description']}\")\n",
      "        print(f\"Temperature: {weather_data['main']['temp']}K\")\n",
      "\n",
      "def main():\n",
      "    api_key = \"YOUR_API_KEY_HERE\"\n",
      "    city = \"London\"\n",
      "    weather_checker = WeatherChecker(api_key)\n",
      "    weather_data = weather_checker.get_weather(city)\n",
      "    weather_checker.print_weather(weather_data)\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n",
      "\n",
      "import unittest\n",
      "class TestWeatherChecker(unittest.TestCase):\n",
      "    def test_get_weather(self):\n",
      "        api_key = \"YOUR_API_KEY_HERE\"\n",
      "        city = \"London\"\n",
      "        weather_checker = WeatherChecker(api_key)\n",
      "        weather_data = weather_checker.get_weather(city)\n",
      "        self.assertGreater(len(weather_data), 0)\n",
      "\n",
      "    def test_print_weather(self):\n",
      "        api_key = \"YOUR_API_KEY_HERE\"\n",
      "        city = \"London\"\n",
      "        weather_checker = WeatherChecker(api_key)\n",
      "        weather_data = {\"name\": \"London\", \"weather\": [{\"description\": \"Sunny\"}], \"main\": {\"temp\": 293.15}}\n",
      "        weather_checker.print_weather(weather_data)\n",
      "\n",
      "if __name__ == \"__test__\":\n",
      "    unittest.main()\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "coder = CodingAgent(\"llama3:8b\")\n",
    "code = coder.ask(\"A simple script to check the current weather.\")\n",
    "print(code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output from the Mistralv0.2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Calculator class definition\n",
      "class Calculator:\n",
      "    def __init__(self):\n",
      "        self.history = []\n",
      "\n",
      "    def add(self, a, b):\n",
      "        result = a + b\n",
      "        self.history.append((a, '+', b, result))\n",
      "        return result\n",
      "\n",
      "    def subtract(self, a, b):\n",
      "        result = a - b\n",
      "        self.history.append((a, '-', b, result))\n",
      "        return result\n",
      "\n",
      "    def multiply(self, a, b):\n",
      "        result = a * b\n",
      "        self.history.append((a, '*', b, result))\n",
      "        return result\n",
      "\n",
      "    def divide(self, a, b):\n",
      "        if b == 0:\n",
      "            raise ValueError(\"Division by zero is not allowed.\")\n",
      "        result = a / b\n",
      "        self.history.append((a, '/', b, result))\n",
      "        return result\n",
      "\n",
      "    def display_history(self):\n",
      "        for entry in reversed(self.history):\n",
      "            print(f\"{entry[0]} {entry[1]} {entry[2]} = {entry[3]}\")\n",
      "\n",
      "# Unit tests\n",
      "def test_calculator():\n",
      "    calc = Calculator()\n",
      "\n",
      "    # Addition test\n",
      "    assert calc.add(2, 3) == 5\n",
      "    assert calc.add(-2, -3) == 1\n",
      "\n",
      "    # Subtraction test\n",
      "    assert calc.subtract(5, 3) == 2\n",
      "    assert calc.subtract(-5, -3) == -2\n",
      "\n",
      "    # Multiplication test\n",
      "    assert calc.multiply(2, 3) == 6\n",
      "    assert calc.multiply(-2, 3) == -6\n",
      "\n",
      "    # Division test\n",
      "    assert calc.divide(10, 5) == 2\n",
      "    assert calc.divide(-10, -5) == 2\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    calculator = Calculator()\n",
      "    test_calculator()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "coder = CodingAgent(\"mistral:v0.2\")\n",
    "code = coder.ask(\"A scientific calculator.\")\n",
    "print(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "class CodingAgent:\n",
    "\n",
    "    def __init__(self, model_name):\n",
    "        self.role = \"\"\"You are a senior developer who writes efficient and neat code for problems\n",
    "        and can teach a junior developer how to code. Your language of choice is Python. Don't explain\n",
    "        the code, just generate the code block itself.\"\"\"\n",
    "        self.llm = Ollama(model=model_name)\n",
    "        self.context_history = {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.context_history = {}\n",
    "\n",
    "    def _parse_code(self, ans):\n",
    "        pattern = r\"```python(.*?)```\"\n",
    "        matches = re.findall(pattern, ans, re.DOTALL)\n",
    "        return matches if matches else [ans]\n",
    "\n",
    "    def write_code(self, instruction):\n",
    "        # Include previous context in the prompt\n",
    "        context = \"\\n\".join(self.context_history.get(\"code_snippets\", []))\n",
    "        self.prompt = f\"\"\"\n",
    "        Context:\n",
    "        {context}\n",
    "        Write a python function that can {instruction}.\n",
    "        Return ```python your_code_here ``` with NO other texts,\n",
    "        your code:\n",
    "        \"\"\"\n",
    "        ans = self.llm.invoke(self.prompt, stop=['<|eot_id|>'])\n",
    "        code_texts = self._parse_code(ans)\n",
    "        \n",
    "        # Update context history with new code\n",
    "        self.context_history.setdefault(\"code_snippets\", []).extend(code_texts)\n",
    "        return code_texts\n",
    "\n",
    "    def summarize_issue(self, issue_text):\n",
    "        self.prompt = f\"\"\" Summarize the following GitHub issue:\n",
    "        Issue:\n",
    "        {issue_text}\n",
    "        Summary:\n",
    "        \"\"\"\n",
    "\n",
    "        # print(self.prompt)\n",
    "        \n",
    "        ans = self.llm.invoke(self.prompt, stop=['<|eot_id|>'])\n",
    "        issue_summary = ans.strip()\n",
    "        \n",
    "        # Update context history with issue summary\n",
    "        self.context_history[\"issue_summary\"] = issue_summary\n",
    "        return issue_summary\n",
    "\n",
    "    def plan_approach(self, issue_summary):\n",
    "        self.prompt = f\"\"\" Given the following issue summary, plan out the approach to solve it:\n",
    "        Summary:\n",
    "        {issue_summary}\n",
    "        Approach:\n",
    "        \"\"\"\n",
    "        ans = self.llm.invoke(self.prompt, stop=['<|eot_id|>'])\n",
    "        approach = ans.strip()\n",
    "        \n",
    "        # Update context history with approach\n",
    "        self.context_history[\"approach\"] = approach\n",
    "        return approach\n",
    "\n",
    "    def create_pull_request_summary(self):\n",
    "        issue_summary = self.context_history.get(\"issue_summary\", \"\")\n",
    "        approach = self.context_history.get(\"approach\", \"\")\n",
    "        code_snippets = self.context_history.get(\"code_snippets\", [])\n",
    "        \n",
    "        code_summary = \"\\n\".join(f\"Function {i+1}:\\n{code}\" for i, code in enumerate(code_snippets))\n",
    "        self.prompt = f\"\"\" Create a pull request summary for the following:\n",
    "        Issue Summary:\n",
    "        {issue_summary}\n",
    "        Approach:\n",
    "        {approach}\n",
    "        Code:\n",
    "        {code_summary}\n",
    "        Pull Request Summary:\n",
    "        \"\"\"\n",
    "        ans = self.llm.invoke(self.prompt, stop=['<|eot_id|>'])\n",
    "        # print(\"Summarized Issue :\", ans)\n",
    "        return ans.strip()\n",
    "\n",
    "    def contribute_to_issue(self, issue_text):\n",
    "        # Summarize the issue\n",
    "        issue_summary = self.summarize_issue(issue_text)\n",
    "        print(issue_text, issue_summary)\n",
    "        \n",
    "        # Plan the approach\n",
    "        approach = self.plan_approach(issue_summary)\n",
    "        print(approach)\n",
    "        \n",
    "        # Split the approach into individual tasks/instructions\n",
    "        tasks = approach.split('. ')  # Assuming each step ends with a period and space\n",
    "        print(tasks)\n",
    "\n",
    "        code_snippets = []\n",
    "        # Write code for each instruction step-by-step\n",
    "        for task in tasks:\n",
    "            if task.strip():  # Ensure task is not empty\n",
    "                code = self.write_code(task)\n",
    "                code_snippets.append(code)\n",
    "                \n",
    "        # Summarize in a pull request\n",
    "        pr_summary = self.create_pull_request_summary()\n",
    "        \n",
    "        # return {\n",
    "        #     \"issue_summary\": issue_summary,\n",
    "        #     \"approach\": approach,\n",
    "        #     \"code_snippets\": self.context_history.get(\"code_snippets\", []),\n",
    "        #     \"pull_request_summary\": pr_summary\n",
    "        # }\n",
    "\n",
    "        return pr_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Issue: Implement a Simple Blogging Platform\n",
      "\n",
      "## Description\n",
      "We need to implement a simple blogging platform with the following features:\n",
      "1. Users can create an account and log in.\n",
      "2. Authenticated users can create, edit, and delete their blog posts.\n",
      "3. Blog posts should support Markdown for formatting.\n",
      "4. Implement a public-facing page where all blog posts are listed.\n",
      "5. Each blog post should have a unique URL for sharing.\n",
      "\n",
      "## Requirements\n",
      "1. User authentication system (sign up, login, logout).\n",
      "2. Blog post CRUD operations (create, read, update, delete).\n",
      "3. Markdown support for blog posts The issue is to implement a simple blogging platform with the following features:\n",
      "\n",
      "* Users can create an account and log in.\n",
      "* Authenticated users can create, edit, and delete their own blog posts.\n",
      "* Blog posts support Markdown formatting.\n",
      "* A public-facing page lists all blog posts.\n",
      "* Each blog post has a unique URL for sharing.\n",
      "\n",
      "The requirements include:\n",
      "\n",
      "1. A user authentication system (sign up, login, logout).\n",
      "2. CRUD operations for blog posts (create, read, update, delete).\n",
      "3. Support for Markdown in blog posts.\n",
      "Here's a high-level approach to solve the issue:\n",
      "\n",
      "**Step 1: Plan the Technology Stack**\n",
      "\n",
      "* Choose a web framework (e.g., Flask or Django) and a database management system (e.g., SQLite or PostgreSQL).\n",
      "* Decide on a templating engine (e.g., Jinja2 or Mako).\n",
      "\n",
      "**Step 2: Implement User Authentication**\n",
      "\n",
      "* Use a library or module that provides user authentication functionality, such as Flask-Login or Django's built-in authentication system.\n",
      "* Implement user sign-up and login functionality using the chosen framework and database management system.\n",
      "\n",
      "**Step 3: Design the Blog Post Model**\n",
      "\n",
      "* Define a Python class or data model to represent a blog post, including attributes such as:\n",
      "\t+ Title\n",
      "\t+ Content (Markdown-formatted text)\n",
      "\t+ Created date and time\n",
      "\t+ Updated date and time\n",
      "\t+ User ID (foreign key referencing the user who created the post)\n",
      "\n",
      "**Step 4: Implement CRUD Operations for Blog Posts**\n",
      "\n",
      "* Create API endpoints or views to handle create, read, update, and delete operations on blog posts:\n",
      "\t+ Create: Allow authenticated users to submit new blog posts with title, content, and optional tags.\n",
      "\t+ Read: Display a list of all blog posts, with each post including its title, content, and creation date. Allow users to view individual blog posts by their unique URLs.\n",
      "\t+ Update: Enable authenticated users to edit their own blog posts.\n",
      "\t+ Delete: Allow authenticated users to delete their own blog posts.\n",
      "\n",
      "**Step 5: Add Markdown Support**\n",
      "\n",
      "* Use a library (e.g., Python-Markdown) to render Markdown-formatted text in blog post content.\n",
      "\n",
      "**Step 6: Implement Public-Facing Page for Blog Posts**\n",
      "\n",
      "* Create an API endpoint or view that returns a list of all blog posts, along with their titles and URLs.\n",
      "* Design a template (using the chosen templating engine) to display this list of blog posts on the public-facing page.\n",
      "\n",
      "**Step 7: Test and Refine**\n",
      "\n",
      "* Implement unit tests for each component of the application (e.g., user authentication, CRUD operations).\n",
      "* Conduct integration testing to ensure that all features work together seamlessly.\n",
      "* Refine the application based on feedback and bug reports.\n",
      "\n",
      "This approach provides a solid foundation for building a simple blogging platform with the required features.\n",
      "[\"Here's a high-level approach to solve the issue:\\n\\n**Step 1: Plan the Technology Stack**\\n\\n* Choose a web framework (e.g., Flask or Django) and a database management system (e.g., SQLite or PostgreSQL).\\n* Decide on a templating engine (e.g., Jinja2 or Mako).\\n\\n**Step 2: Implement User Authentication**\\n\\n* Use a library or module that provides user authentication functionality, such as Flask-Login or Django's built-in authentication system.\\n* Implement user sign-up and login functionality using the chosen framework and database management system.\\n\\n**Step 3: Design the Blog Post Model**\\n\\n* Define a Python class or data model to represent a blog post, including attributes such as:\\n\\t+ Title\\n\\t+ Content (Markdown-formatted text)\\n\\t+ Created date and time\\n\\t+ Updated date and time\\n\\t+ User ID (foreign key referencing the user who created the post)\\n\\n**Step 4: Implement CRUD Operations for Blog Posts**\\n\\n* Create API endpoints or views to handle create, read, update, and delete operations on blog posts:\\n\\t+ Create: Allow authenticated users to submit new blog posts with title, content, and optional tags.\\n\\t+ Read: Display a list of all blog posts, with each post including its title, content, and creation date\", 'Allow users to view individual blog posts by their unique URLs.\\n\\t+ Update: Enable authenticated users to edit their own blog posts.\\n\\t+ Delete: Allow authenticated users to delete their own blog posts.\\n\\n**Step 5: Add Markdown Support**\\n\\n* Use a library (e.g., Python-Markdown) to render Markdown-formatted text in blog post content.\\n\\n**Step 6: Implement Public-Facing Page for Blog Posts**\\n\\n* Create an API endpoint or view that returns a list of all blog posts, along with their titles and URLs.\\n* Design a template (using the chosen templating engine) to display this list of blog posts on the public-facing page.\\n\\n**Step 7: Test and Refine**\\n\\n* Implement unit tests for each component of the application (e.g., user authentication, CRUD operations).\\n* Conduct integration testing to ensure that all features work together seamlessly.\\n* Refine the application based on feedback and bug reports.\\n\\nThis approach provides a solid foundation for building a simple blogging platform with the required features.']\n",
      "Here is a summary for the pull request:\n",
      "\n",
      "**Title:** Implement Simple Blogging Platform with User Authentication and CRUD Operations\n",
      "\n",
      "**Description:** This pull request implements a simple blogging platform with user authentication, CRUD (Create, Read, Update, Delete) operations, and support for Markdown formatting. The platform allows users to create an account, log in, create and edit their own blog posts, and delete their own posts.\n",
      "\n",
      "**Changes:**\n",
      "\n",
      "* Implemented user authentication system using Flask-Login\n",
      "* Created API endpoints and views for CRUD operations on blog posts\n",
      "* Added support for Markdown formatting in blog post content using Python-Markdown\n",
      "* Designed templates for displaying blog posts and implementing public-facing page\n",
      "* Wrote unit tests and conducted integration testing to ensure the application works as expected\n",
      "\n",
      "**Code Changes:**\n",
      "\n",
      "* Function 1: Added API endpoints and views for creating, reading, updating, and deleting blog posts\n",
      "* Function 2: Implemented view and edit functions for individual blog posts\n",
      "\n",
      "**Why this PR is important:** This pull request provides a solid foundation for building a simple blogging platform with the required features. It demonstrates best practices in designing and implementing a web application, including user authentication, CRUD operations, and support for Markdown formatting.\n",
      "\n",
      "**What's next:**\n",
      "\n",
      "* Review and test the code changes\n",
      "* Address any feedback or concerns from the community\n",
      "* Refine the application based on bug reports and feedback\n",
      "\n",
      "I hope this summary is helpful! Let me know if you have any further questions.\n",
      "\"Here is a summary for the pull request:\\n\\n**Title:** Implement Simple Blogging Platform with User Authentication and CRUD Operations\\n\\n**Description:** This pull request implements a simple blogging platform with user authentication, CRUD (Create, Read, Update, Delete) operations, and support for Markdown formatting. The platform allows users to create an account, log in, create and edit their own blog posts, and delete their own posts.\\n\\n**Changes:**\\n\\n* Implemented user authentication system using Flask-Login\\n* Created API endpoints and views for CRUD operations on blog posts\\n* Added support for Markdown formatting in blog post content using Python-Markdown\\n* Designed templates for displaying blog posts and implementing public-facing page\\n* Wrote unit tests and conducted integration testing to ensure the application works as expected\\n\\n**Code Changes:**\\n\\n* Function 1: Added API endpoints and views for creating, reading, updating, and deleting blog posts\\n* Function 2: Implemented view and edit functions for individual blog posts\\n\\n**Why this PR is important:** This pull request provides a solid foundation for building a simple blogging platform with the required features. It demonstrates best practices in designing and implementing a web application, including user authentication, CRUD operations, and support for Markdown formatting.\\n\\n**What's next:**\\n\\n* Review and test the code changes\\n* Address any feedback or concerns from the community\\n* Refine the application based on bug reports and feedback\\n\\nI hope this summary is helpful! Let me know if you have any further questions.\"\n"
     ]
    }
   ],
   "source": [
    "agent = CodingAgent(model_name=\"llama3:8b\")\n",
    "issue_text = \"\"\"\n",
    "# Issue: Implement a Simple Blogging Platform\n",
    "\n",
    "## Description\n",
    "We need to implement a simple blogging platform with the following features:\n",
    "1. Users can create an account and log in.\n",
    "2. Authenticated users can create, edit, and delete their blog posts.\n",
    "3. Blog posts should support Markdown for formatting.\n",
    "4. Implement a public-facing page where all blog posts are listed.\n",
    "5. Each blog post should have a unique URL for sharing.\n",
    "\n",
    "## Requirements\n",
    "1. User authentication system (sign up, login, logout).\n",
    "2. Blog post CRUD operations (create, read, update, delete).\n",
    "3. Markdown support for blog posts\"\"\"\n",
    "contribution = agent.contribute_to_issue(issue_text)\n",
    "print(contribution)\n",
    "print(json.dumps(contribution, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\nfrom flask import Flask, request, jsonify\\nfrom flask_sqlalchemy import SQLAlchemy\\nfrom flask_marshmallow import Marshmallow\\n\\napp = Flask(__name__)\\napp.config[\"SQLALCHEMY_DATABASE_URI\"] = \"sqlite:////tmp/test.db\"\\ndb = SQLAlchemy(app)\\nma = Marshmallow(app)\\n\\nclass BlogPost(db.Model):\\n    id = db.Column(db.Integer, primary_key=True)\\n    title = db.Column(db.String(100), nullable=False)\\n    content = db.Column(db.Text, nullable=False)\\n    created_date = db.Column(db.DateTime, default=db.func.current_timestamp())\\n    updated_date = db.Column(db.DateTime, default=db.func.current_timestamp(), onupdate=db.func.current_timestamp())\\n    user_id = db.Column(db.Integer, db.ForeignKey(\"user.id\"), nullable=False)\\n\\nclass BlogPostSchema(ma.Schema):\\n    class Meta:\\n        fields = (\"id\", \"title\", \"content\", \"created_date\", \"updated_date\", \"user_id\")\\n\\nblog_post_schema = BlogPostSchema()\\nmultiple_blog_posts_schema = BlogPostSchema(many=True)\\n\\n@app.route(\"/blog_post\", methods=[\"POST\"])\\ndef create_blog_post():\\n    data = request.get_json()\\n    new_blog_post = BlogPost(title=data[\"title\"], content=data[\"content\"], user_id=data[\"user_id\"])\\n    db.session.add(new_blog_post)\\n    db.session.commit()\\n    return blog_post_schema.jsonify(new_blog_post)\\n\\n@app.route(\"/blog_post\", methods=[\"GET\"])\\ndef get_all_blog_posts():\\n    all_blog_posts = BlogPost.query.all()\\n    result = multiple_blog_posts_schema.dump(all_blog_posts)\\n    return jsonify(result)\\n\\n@app.route(\"/blog_post/<int:blog_post_id>\", methods=[\"GET\"])\\ndef get_single_blog_post(blog_post_id):\\n    blog_post = BlogPost.query.get(blog_post_id)\\n    if not blog_post:\\n        return jsonify({\"message\": \"Blog post not found\"}), 404\\n    result = blog_post_schema.dump(blog_post)\\n    return jsonify(result)\\n\\n@app.route(\"/blog_post/<int:blog_post_id>\", methods=[\"PUT\"])\\ndef update_blog_post(blog_post_id):\\n    blog_post = BlogPost.query.get(blog_post_id)\\n    if not blog_post:\\n        return jsonify({\"message\": \"Blog post not found\"}), 404\\n    data = request.get_json()\\n    blog_post.title = data[\"title\"]\\n    blog_post.content = data[\"content\"]\\n    db.session.commit()\\n    result = blog_post_schema.dump(blog_post)\\n    return jsonify(result)\\n\\n@app.route(\"/blog_post/<int:blog_post_id>\", methods=[\"DELETE\"])\\ndef delete_blog_post(blog_post_id):\\n    blog_post = BlogPost.query.get(blog_post_id)\\n    if not blog_post:\\n        return jsonify({\"message\": \"Blog post not found\"}), 404\\n    db.session.delete(blog_post)\\n    db.session.commit()\\n    return jsonify({\"message\": \"Blog post deleted\"})\\n\\nif __name__ == \"__main__\":\\n    app.run(debug=True, port=5000)\\n', '```\\ndef view_blog_post(blog_post_id):\\n    blog_post = BlogPost.query.get(blog_post_id)\\n    if not blog_post:\\n        return jsonify({\"message\": \"Blog post not found\"}), 404\\n    result = blog_post_schema.dump(blog_post)\\n    return jsonify(result)\\n\\n@app.route(\\'/blog_post/<int:blog_post_id>\\', methods=[\\'GET\\'])\\ndef view_individual_blog_post(blog_post_id):\\n    return view_blog_post(blog_post_id)\\n\\n@app.route(\\'/edit_blog_post\\', methods=[\\'PUT\\'])\\ndef edit_blog_post():\\n    data = request.get_json()\\n    blog_post_id = data[\\'id\\']\\n    blog_post = BlogPost.query.get(blog_post_id)\\n    if not blog_post:\\n        return jsonify({\"message\": \"Blog post not found\"}), 404\\n    blog_post.title = data[\\'title\\']\\n    blog_post.content = data[\\'content\\']\\n    db.session.commit()\\n    result = blog_post_schema.dump(blog_post)\\n    return jsonify(result)\\n\\n@app.route(\\'/delete_blog_post\\', methods=[\\'DELETE\\'])\\ndef delete_blog_post():\\n    data = request.get_json()\\n    blog_post_id = data[\\'id\\']\\n    blog_post = BlogPost.query.get(blog_post_id)\\n    if not blog_post:\\n        return jsonify({\"message\": \"Blog post not found\"}), 404\\n    db.session.delete(blog_post)\\n    db.session.commit()\\n    return jsonify({\"message\": \"Blog post deleted\"})\\n```']\n"
     ]
    }
   ],
   "source": [
    "code_snippets = agent.context_history.get(\"code_snippets\", [])\n",
    "print(code_snippets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversation ability \n",
    "1. Understanding context using Retreival Augmented Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: slack-sdk in c:\\users\\sarrah\\data_win\\personal_projects\\gsoc_24\\gsoc24\\lib\\site-packages (3.27.2)\n",
      "Requirement already satisfied: pypdf in c:\\users\\sarrah\\data_win\\personal_projects\\gsoc_24\\gsoc24\\lib\\site-packages (4.2.0)\n",
      "Collecting chromadb\n",
      "  Downloading chromadb-0.5.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting build>=1.0.3 (from chromadb)\n",
      "  Downloading build-1.2.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: requests>=2.28 in c:\\users\\sarrah\\data_win\\personal_projects\\gsoc_24\\gsoc24\\lib\\site-packages (from chromadb) (2.32.3)\n",
      "Requirement already satisfied: pydantic>=1.9 in c:\\users\\sarrah\\data_win\\personal_projects\\gsoc_24\\gsoc24\\lib\\site-packages (from chromadb) (2.7.3)\n",
      "Collecting chroma-hnswlib==0.7.3 (from chromadb)\n",
      "  Downloading chroma_hnswlib-0.7.3-cp311-cp311-win_amd64.whl.metadata (262 bytes)\n",
      "Collecting fastapi>=0.95.2 (from chromadb)\n",
      "  Downloading fastapi-0.111.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading uvicorn-0.30.1-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.22.5 in c:\\users\\sarrah\\data_win\\personal_projects\\gsoc_24\\gsoc24\\lib\\site-packages (from chromadb) (1.26.4)\n",
      "Collecting posthog>=2.4.0 (from chromadb)\n",
      "  Downloading posthog-3.5.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\sarrah\\data_win\\personal_projects\\gsoc_24\\gsoc24\\lib\\site-packages (from chromadb) (4.12.1)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Using cached onnxruntime-1.18.0-cp311-cp311-win_amd64.whl.metadata (4.4 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_api-1.25.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.25.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.46b0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_sdk-1.25.0-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting tokenizers>=0.13.2 (from chromadb)\n",
      "  Using cached tokenizers-0.19.1-cp311-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "     ---------------------------------------- 0.0/67.3 kB ? eta -:--:--\n",
      "     ------------------------------------ --- 61.4/67.3 kB 1.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 67.3/67.3 kB 1.8 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting tqdm>=4.65.0 (from chromadb)\n",
      "  Using cached tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting overrides>=7.3.1 (from chromadb)\n",
      "  Using cached overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting importlib-resources (from chromadb)\n",
      "  Downloading importlib_resources-6.4.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting grpcio>=1.58.0 (from chromadb)\n",
      "  Downloading grpcio-1.64.1-cp311-cp311-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Downloading bcrypt-4.1.3-cp39-abi3-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb)\n",
      "  Downloading typer-0.12.3-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Downloading kubernetes-30.1.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in c:\\users\\sarrah\\data_win\\personal_projects\\gsoc_24\\gsoc24\\lib\\site-packages (from chromadb) (8.3.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in c:\\users\\sarrah\\data_win\\personal_projects\\gsoc_24\\gsoc24\\lib\\site-packages (from chromadb) (6.0.1)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Using cached mmh3-4.1.0-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\sarrah\\data_win\\personal_projects\\gsoc_24\\gsoc24\\lib\\site-packages (from chromadb) (3.10.3)\n",
      "Requirement already satisfied: packaging>=19.1 in c:\\users\\sarrah\\data_win\\personal_projects\\gsoc_24\\gsoc24\\lib\\site-packages (from build>=1.0.3->chromadb) (23.2)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
      "  Downloading pyproject_hooks-1.1.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting colorama (from build>=1.0.3->chromadb)\n",
      "  Using cached colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
      "Collecting starlette<0.38.0,>=0.37.2 (from fastapi>=0.95.2->chromadb)\n",
      "  Downloading starlette-0.37.2-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting fastapi-cli>=0.0.2 (from fastapi>=0.95.2->chromadb)\n",
      "  Downloading fastapi_cli-0.0.4-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting httpx>=0.23.0 (from fastapi>=0.95.2->chromadb)\n",
      "  Using cached httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting jinja2>=2.11.2 (from fastapi>=0.95.2->chromadb)\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting python-multipart>=0.0.7 (from fastapi>=0.95.2->chromadb)\n",
      "  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 (from fastapi>=0.95.2->chromadb)\n",
      "  Downloading ujson-5.10.0-cp311-cp311-win_amd64.whl.metadata (9.5 kB)\n",
      "Collecting email_validator>=2.0.0 (from fastapi>=0.95.2->chromadb)\n",
      "  Downloading email_validator-2.1.1-py3-none-any.whl.metadata (26 kB)\n",
      "Requirement already satisfied: certifi>=14.05.14 in c:\\users\\sarrah\\data_win\\personal_projects\\gsoc_24\\gsoc24\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2024.6.2)\n",
      "Collecting six>=1.9.0 (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached six-1.16.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting python-dateutil>=2.5.3 (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading google_auth-2.30.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 (from kubernetes>=28.1.0->chromadb)\n",
      "  Using cached websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\sarrah\\data_win\\personal_projects\\gsoc_24\\gsoc24\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.2.1)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached protobuf-5.27.1-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting sympy (from onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached sympy-1.12.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting importlib-metadata<=7.1,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading importlib_metadata-7.1.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading googleapis_common_protos-1.63.1-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.25.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.25.0-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting opentelemetry-proto==1.25.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_proto-1.25.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading protobuf-4.25.3-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.46b0-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-instrumentation==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation-0.46b0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_semantic_conventions-0.46b0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting opentelemetry-util-http==0.46b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_util_http-0.46b0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: setuptools>=16.0 in c:\\users\\sarrah\\data_win\\personal_projects\\gsoc_24\\gsoc24\\lib\\site-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (65.5.0)\n",
      "Collecting wrapt<2.0.0,>=1.0.0 (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading wrapt-1.16.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\sarrah\\data_win\\personal_projects\\gsoc_24\\gsoc24\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.4 in c:\\users\\sarrah\\data_win\\personal_projects\\gsoc_24\\gsoc24\\lib\\site-packages (from pydantic>=1.9->chromadb) (2.18.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sarrah\\data_win\\personal_projects\\gsoc_24\\gsoc24\\lib\\site-packages (from requests>=2.28->chromadb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sarrah\\data_win\\personal_projects\\gsoc_24\\gsoc24\\lib\\site-packages (from requests>=2.28->chromadb) (3.7)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from tokenizers>=0.13.2->chromadb)\n",
      "  Using cached huggingface_hub-0.23.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting click>=8.0.0 (from typer>=0.9.0->chromadb)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer>=0.9.0->chromadb)\n",
      "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting h11>=0.8 (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading httptools-0.6.1-cp311-cp311-win_amd64.whl.metadata (3.7 kB)\n",
      "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading watchfiles-0.22.0-cp311-none-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading websockets-12.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi>=0.95.2->chromadb)\n",
      "  Downloading dnspython-2.6.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading cachetools-5.3.3-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading pyasn1_modules-0.4.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting anyio (from httpx>=0.23.0->fastapi>=0.95.2->chromadb)\n",
      "  Downloading anyio-4.4.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting httpcore==1.* (from httpx>=0.23.0->fastapi>=0.95.2->chromadb)\n",
      "  Using cached httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting sniffio (from httpx>=0.23.0->fastapi>=0.95.2->chromadb)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting filelock (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb)\n",
      "  Using cached filelock-3.14.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb)\n",
      "  Using cached fsspec-2024.6.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting zipp>=0.5 (from importlib-metadata<=7.1,>=6.0->opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading zipp-3.19.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2>=2.11.2->fastapi>=0.95.2->chromadb)\n",
      "  Using cached MarkupSafe-2.1.5-cp311-cp311-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer>=0.9.0->chromadb)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting pygments<3.0.0,>=2.13.0 (from rich>=10.11.0->typer>=0.9.0->chromadb)\n",
      "  Using cached pygments-2.18.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting mpmath<1.4.0,>=1.1.0 (from sympy->onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Using cached pyreadline3-3.4.1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
      "  Downloading pyasn1-0.6.0-py2.py3-none-any.whl.metadata (8.3 kB)\n",
      "Downloading chromadb-0.5.0-py3-none-any.whl (526 kB)\n",
      "   ---------------------------------------- 0.0/526.8 kB ? eta -:--:--\n",
      "   ------ --------------------------------- 81.9/526.8 kB 1.5 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 163.8/526.8 kB 1.6 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 225.3/526.8 kB 1.5 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 327.7/526.8 kB 1.7 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 409.6/526.8 kB 1.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 491.5/526.8 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 526.8/526.8 kB 1.7 MB/s eta 0:00:00\n",
      "Downloading chroma_hnswlib-0.7.3-cp311-cp311-win_amd64.whl (151 kB)\n",
      "   ---------------------------------------- 0.0/151.6 kB ? eta -:--:--\n",
      "   ---------------- ----------------------- 61.4/151.6 kB 3.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 143.4/151.6 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 151.6/151.6 kB 1.3 MB/s eta 0:00:00\n",
      "Downloading bcrypt-4.1.3-cp39-abi3-win_amd64.whl (158 kB)\n",
      "   ---------------------------------------- 0.0/158.1 kB ? eta -:--:--\n",
      "   ----------------------- ---------------- 92.2/158.1 kB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 158.1/158.1 kB 2.4 MB/s eta 0:00:00\n",
      "Downloading build-1.2.1-py3-none-any.whl (21 kB)\n",
      "Downloading fastapi-0.111.0-py3-none-any.whl (91 kB)\n",
      "   ---------------------------------------- 0.0/92.0 kB ? eta -:--:--\n",
      "   ----------------------------------- ---- 81.9/92.0 kB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 92.0/92.0 kB 1.7 MB/s eta 0:00:00\n",
      "Downloading grpcio-1.64.1-cp311-cp311-win_amd64.whl (4.1 MB)\n",
      "   ---------------------------------------- 0.0/4.1 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.1/4.1 MB 2.3 MB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.2/4.1 MB 2.4 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.3/4.1 MB 2.1 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.4/4.1 MB 2.3 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 0.5/4.1 MB 2.3 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.6/4.1 MB 2.2 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 0.7/4.1 MB 2.3 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 0.8/4.1 MB 2.3 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 0.9/4.1 MB 2.3 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 1.1/4.1 MB 2.3 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 1.2/4.1 MB 2.3 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 1.3/4.1 MB 2.3 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 1.4/4.1 MB 2.4 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 1.6/4.1 MB 2.4 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 1.7/4.1 MB 2.5 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 1.8/4.1 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.9/4.1 MB 2.5 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 2.1/4.1 MB 2.5 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 2.2/4.1 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 2.3/4.1 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 2.5/4.1 MB 2.5 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 2.6/4.1 MB 2.6 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 2.7/4.1 MB 2.6 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 2.8/4.1 MB 2.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 2.9/4.1 MB 2.6 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 3.1/4.1 MB 2.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 3.3/4.1 MB 2.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 3.4/4.1 MB 2.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 3.5/4.1 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 3.7/4.1 MB 2.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 3.8/4.1 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.0/4.1 MB 2.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.1/4.1 MB 2.7 MB/s eta 0:00:00\n",
      "Downloading kubernetes-30.1.0-py2.py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.2/1.7 MB 4.6 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 0.3/1.7 MB 3.8 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.5/1.7 MB 3.7 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.6/1.7 MB 3.5 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 0.8/1.7 MB 3.7 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 0.8/1.7 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 0.9/1.7 MB 3.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.1/1.7 MB 3.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 1.3/1.7 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.5/1.7 MB 3.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 1.6/1.7 MB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 3.2 MB/s eta 0:00:00\n",
      "Using cached mmh3-4.1.0-cp311-cp311-win_amd64.whl (31 kB)\n",
      "Using cached onnxruntime-1.18.0-cp311-cp311-win_amd64.whl (5.6 MB)\n",
      "Downloading opentelemetry_api-1.25.0-py3-none-any.whl (59 kB)\n",
      "   ---------------------------------------- 0.0/59.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 59.9/59.9 kB 1.6 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_exporter_otlp_proto_grpc-1.25.0-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.25.0-py3-none-any.whl (17 kB)\n",
      "Downloading opentelemetry_proto-1.25.0-py3-none-any.whl (52 kB)\n",
      "   ---------------------------------------- 0.0/52.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 52.5/52.5 kB 2.6 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_instrumentation_fastapi-0.46b0-py3-none-any.whl (11 kB)\n",
      "Downloading opentelemetry_instrumentation-0.46b0-py3-none-any.whl (29 kB)\n",
      "Downloading opentelemetry_instrumentation_asgi-0.46b0-py3-none-any.whl (14 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.46b0-py3-none-any.whl (130 kB)\n",
      "   ---------------------------------------- 0.0/130.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 130.5/130.5 kB 2.6 MB/s eta 0:00:00\n",
      "Downloading opentelemetry_util_http-0.46b0-py3-none-any.whl (6.9 kB)\n",
      "Downloading opentelemetry_sdk-1.25.0-py3-none-any.whl (107 kB)\n",
      "   ---------------------------------------- 0.0/107.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 107.0/107.0 kB 6.0 MB/s eta 0:00:00\n",
      "Using cached overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Downloading posthog-3.5.0-py2.py3-none-any.whl (41 kB)\n",
      "   ---------------------------------------- 0.0/41.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 41.3/41.3 kB 970.6 kB/s eta 0:00:00\n",
      "Using cached tokenizers-0.19.1-cp311-none-win_amd64.whl (2.2 MB)\n",
      "Using cached tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "Downloading typer-0.12.3-py3-none-any.whl (47 kB)\n",
      "   ---------------------------------------- 0.0/47.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 47.2/47.2 kB 2.5 MB/s eta 0:00:00\n",
      "Downloading uvicorn-0.30.1-py3-none-any.whl (62 kB)\n",
      "   ---------------------------------------- 0.0/62.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 62.4/62.4 kB 3.3 MB/s eta 0:00:00\n",
      "Downloading importlib_resources-6.4.0-py3-none-any.whl (38 kB)\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "   ---------------------------------------- 0.0/97.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 97.9/97.9 kB 2.8 MB/s eta 0:00:00\n",
      "Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
      "Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading email_validator-2.1.1-py3-none-any.whl (30 kB)\n",
      "Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
      "Downloading google_auth-2.30.0-py2.py3-none-any.whl (193 kB)\n",
      "   ---------------------------------------- 0.0/193.7 kB ? eta -:--:--\n",
      "   ----------------------------- ---------- 143.4/193.7 kB 8.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 193.7/193.7 kB 3.0 MB/s eta 0:00:00\n",
      "Downloading googleapis_common_protos-1.63.1-py2.py3-none-any.whl (229 kB)\n",
      "   ---------------------------------------- 0.0/229.2 kB ? eta -:--:--\n",
      "   ------------------------------ --------- 174.1/229.2 kB 5.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 229.2/229.2 kB 2.8 MB/s eta 0:00:00\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Downloading httptools-0.6.1-cp311-cp311-win_amd64.whl (55 kB)\n",
      "   ---------------------------------------- 0.0/55.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 55.4/55.4 kB 2.8 MB/s eta 0:00:00\n",
      "Using cached httpx-0.27.0-py3-none-any.whl (75 kB)\n",
      "Using cached httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
      "Using cached huggingface_hub-0.23.3-py3-none-any.whl (401 kB)\n",
      "Downloading importlib_metadata-7.1.0-py3-none-any.whl (24 kB)\n",
      "Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "   ---------------------------------------- 0.0/151.7 kB ? eta -:--:--\n",
      "   ------------------------------------- -- 143.4/151.7 kB 4.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 151.7/151.7 kB 3.0 MB/s eta 0:00:00\n",
      "Downloading protobuf-4.25.3-cp310-abi3-win_amd64.whl (413 kB)\n",
      "   ---------------------------------------- 0.0/413.4 kB ? eta -:--:--\n",
      "   ------------- -------------------------- 143.4/413.4 kB 4.3 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 307.2/413.4 kB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 413.4/413.4 kB 3.2 MB/s eta 0:00:00\n",
      "Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
      "Downloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "   ---------------------------------------- 0.0/240.7 kB ? eta -:--:--\n",
      "   -------------------- ------------------- 122.9/240.7 kB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 240.7/240.7 kB 3.7 MB/s eta 0:00:00\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
      "   ---------------------------------------- 0.0/71.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 71.9/71.9 kB 3.9 MB/s eta 0:00:00\n",
      "Downloading ujson-5.10.0-cp311-cp311-win_amd64.whl (42 kB)\n",
      "   ---------------------------------------- 0.0/42.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 42.1/42.1 kB 2.1 MB/s eta 0:00:00\n",
      "Downloading watchfiles-0.22.0-cp311-none-win_amd64.whl (281 kB)\n",
      "   ---------------------------------------- 0.0/282.0 kB ? eta -:--:--\n",
      "   ------------------------------- -------- 225.3/282.0 kB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 282.0/282.0 kB 5.8 MB/s eta 0:00:00\n",
      "Using cached websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "Downloading websockets-12.0-cp311-cp311-win_amd64.whl (124 kB)\n",
      "   ---------------------------------------- 0.0/125.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 125.0/125.0 kB 3.7 MB/s eta 0:00:00\n",
      "Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading pyproject_hooks-1.1.0-py3-none-any.whl (9.2 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Using cached sympy-1.12.1-py3-none-any.whl (5.7 MB)\n",
      "Downloading anyio-4.4.0-py3-none-any.whl (86 kB)\n",
      "   ---------------------------------------- 0.0/86.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 86.8/86.8 kB 5.1 MB/s eta 0:00:00\n",
      "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Downloading cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
      "Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
      "   ---------------------------------------- 0.0/307.7 kB ? eta -:--:--\n",
      "   ---------------------- ----------------- 174.1/307.7 kB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 307.7/307.7 kB 4.7 MB/s eta 0:00:00\n",
      "Using cached fsspec-2024.6.0-py3-none-any.whl (176 kB)\n",
      "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "   ---------------------------------------- 0.0/87.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 87.5/87.5 kB 2.5 MB/s eta 0:00:00\n",
      "Using cached MarkupSafe-2.1.5-cp311-cp311-win_amd64.whl (17 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Downloading pyasn1_modules-0.4.0-py3-none-any.whl (181 kB)\n",
      "   ---------------------------------------- 0.0/181.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 181.2/181.2 kB 5.3 MB/s eta 0:00:00\n",
      "Using cached pygments-2.18.0-py3-none-any.whl (1.2 MB)\n",
      "Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading wrapt-1.16.0-cp311-cp311-win_amd64.whl (37 kB)\n",
      "Downloading zipp-3.19.2-py3-none-any.whl (9.0 kB)\n",
      "Using cached filelock-3.14.0-py3-none-any.whl (12 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading pyasn1-0.6.0-py2.py3-none-any.whl (85 kB)\n",
      "   ---------------------------------------- 0.0/85.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 85.3/85.3 kB 2.4 MB/s eta 0:00:00\n",
      "Using cached pyreadline3-3.4.1-py3-none-any.whl (95 kB)\n",
      "Building wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml): started\n",
      "  Building wheel for pypika (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53835 sha256=d503d455532c1aa894f16a27ea72742b695db9a6c6fb80df86631fdfd8118173\n",
      "  Stored in directory: c:\\users\\sarrah\\appdata\\local\\pip\\cache\\wheels\\a3\\01\\bd\\4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
      "Successfully built pypika\n",
      "Installing collected packages: pyreadline3, pypika, mpmath, monotonic, mmh3, flatbuffers, zipp, wrapt, websockets, websocket-client, ujson, sympy, sniffio, six, shellingham, python-multipart, python-dotenv, pyproject_hooks, pygments, pyasn1, protobuf, overrides, opentelemetry-util-http, oauthlib, mdurl, MarkupSafe, importlib-resources, humanfriendly, httptools, h11, grpcio, fsspec, filelock, dnspython, colorama, chroma-hnswlib, cachetools, bcrypt, backoff, asgiref, tqdm, rsa, requests-oauthlib, python-dateutil, pyasn1-modules, opentelemetry-proto, markdown-it-py, jinja2, importlib-metadata, httpcore, googleapis-common-protos, email_validator, deprecated, coloredlogs, click, build, anyio, watchfiles, uvicorn, starlette, rich, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, onnxruntime, huggingface-hub, httpx, google-auth, typer, tokenizers, opentelemetry-semantic-conventions, opentelemetry-instrumentation, kubernetes, opentelemetry-sdk, opentelemetry-instrumentation-asgi, fastapi-cli, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp-proto-grpc, fastapi, chromadb\n",
      "Successfully installed MarkupSafe-2.1.5 anyio-4.4.0 asgiref-3.8.1 backoff-2.2.1 bcrypt-4.1.3 build-1.2.1 cachetools-5.3.3 chroma-hnswlib-0.7.3 chromadb-0.5.0 click-8.1.7 colorama-0.4.6 coloredlogs-15.0.1 deprecated-1.2.14 dnspython-2.6.1 email_validator-2.1.1 fastapi-0.111.0 fastapi-cli-0.0.4 filelock-3.14.0 flatbuffers-24.3.25 fsspec-2024.6.0 google-auth-2.30.0 googleapis-common-protos-1.63.1 grpcio-1.64.1 h11-0.14.0 httpcore-1.0.5 httptools-0.6.1 httpx-0.27.0 huggingface-hub-0.23.3 humanfriendly-10.0 importlib-metadata-7.1.0 importlib-resources-6.4.0 jinja2-3.1.4 kubernetes-30.1.0 markdown-it-py-3.0.0 mdurl-0.1.2 mmh3-4.1.0 monotonic-1.6 mpmath-1.3.0 oauthlib-3.2.2 onnxruntime-1.18.0 opentelemetry-api-1.25.0 opentelemetry-exporter-otlp-proto-common-1.25.0 opentelemetry-exporter-otlp-proto-grpc-1.25.0 opentelemetry-instrumentation-0.46b0 opentelemetry-instrumentation-asgi-0.46b0 opentelemetry-instrumentation-fastapi-0.46b0 opentelemetry-proto-1.25.0 opentelemetry-sdk-1.25.0 opentelemetry-semantic-conventions-0.46b0 opentelemetry-util-http-0.46b0 overrides-7.7.0 posthog-3.5.0 protobuf-4.25.3 pyasn1-0.6.0 pyasn1-modules-0.4.0 pygments-2.18.0 pypika-0.48.9 pyproject_hooks-1.1.0 pyreadline3-3.4.1 python-dateutil-2.9.0.post0 python-dotenv-1.0.1 python-multipart-0.0.9 requests-oauthlib-2.0.0 rich-13.7.1 rsa-4.9 shellingham-1.5.4 six-1.16.0 sniffio-1.3.1 starlette-0.37.2 sympy-1.12.1 tokenizers-0.19.1 tqdm-4.66.4 typer-0.12.3 ujson-5.10.0 uvicorn-0.30.1 watchfiles-0.22.0 websocket-client-1.8.0 websockets-12.0 wrapt-1.16.0 zipp-3.19.2\n"
     ]
    }
   ],
   "source": [
    "!pip install slack-sdk\n",
    "!pip install pypdf\n",
    "# !pip install fastembed\n",
    "!pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_community.embeddings.ollama import OllamaEmbeddings\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.vectorstores.utils import filter_complex_metadata\n",
    "from langchain.document_loaders.json_loader import JSONLoader\n",
    "from langchain.docstore.document import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatPDF:\n",
    "    vector_store = None\n",
    "    retriever = None\n",
    "    chain = None\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = ChatOllama(model=\"llama3:8b\")\n",
    "        self.text_splitter = RecursiveCharacterTextSplitter(chunk_size=1024, chunk_overlap=100)\n",
    "        self.prompt = PromptTemplate.from_template(\n",
    "            \"\"\"\n",
    "            DOCUMENT:\n",
    "            {context}\n",
    "\n",
    "            QUESTION:\n",
    "            {question}\n",
    "\n",
    "            INSTRUCTIONS:\n",
    "            Answer the users QUESTION \n",
    "            \"\"\"\n",
    "        )\n",
    "        \n",
    "    def ingest(self, docs):\n",
    "        chunks = self.text_splitter.split_documents(docs)\n",
    "        chunks = filter_complex_metadata(chunks)\n",
    "        embeddings = OllamaEmbeddings(model=\"llama3:8b\")\n",
    "        vector_store = Chroma.from_documents(documents=chunks, embedding=embeddings)\n",
    "        self.retriever = vector_store.as_retriever(\n",
    "            search_type=\"similarity_score_threshold\",\n",
    "            search_kwargs={\n",
    "                \"k\": 3,\n",
    "                \"score_threshold\": 0.9,\n",
    "            },\n",
    "        )\n",
    "\n",
    "        self.chain = ({\"context\": self.retriever, \"question\": RunnablePassthrough()}\n",
    "                      | self.prompt\n",
    "                      | self.model\n",
    "                      | StrOutputParser())\n",
    "\n",
    "    def ask(self, query: str):\n",
    "        if not self.chain:\n",
    "            return \"Please, add a document first.\"\n",
    "\n",
    "        return self.chain.invoke(query)\n",
    "\n",
    "    def clear(self):\n",
    "        self.vector_store = None\n",
    "        self.retriever = None\n",
    "        self.chain = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversation data\n",
    "\n",
    "#Later ToDo : Get conversation data from Slack\n",
    "\n",
    "# from slack_sdk import WebClient\n",
    "# import os\n",
    "\n",
    "# client = WebClient(token=os.environ[\"SLACK_BOT_TOKEN\"])\n",
    "# response = client.conversations_info(\n",
    "#     channel=\"C031415926\",\n",
    "#     include_num_members=1\n",
    "# )\n",
    "\n",
    "# Current : Load Sample Conversation Data\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "file_path = r\"C:\\Users\\sarrah\\data_win\\Personal_Projects\\GSoC_24\\preliminary-design\\sample_conversation.json\"\n",
    "data = json.loads(Path(file_path).read_text())\n",
    "\n",
    "texts = []\n",
    "\n",
    "for message in data[\"messages\"]:\n",
    "    user_id = message[\"user\"]\n",
    "    text = message[\"text\"]\n",
    "    timestamp = message[\"ts\"]\n",
    "    team_id = message[\"team\"]\n",
    "    \n",
    "    # Prepare text for embedding\n",
    "    text_to_embed = f\"{user_id} said: {text} at {timestamp} in team {team_id}. Full accompanying message was {message}\"\n",
    "    texts.append(text_to_embed)\n",
    "\n",
    "documents = [Document(page_content=text) for text in texts]\n",
    "\n",
    "chatter = ChatPDF()\n",
    "chatter.ingest(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content=\"U01ABCD2EFG said: Hey team, we need to finalize the project timeline. at 1623948724.000200 in team T01HJKL3MNO. Full accompanying message was {'client_msg_id': 'b0a8c3a5-9330-4e8b-8320-50f84e2cbf77', 'type': 'message', 'text': 'Hey team, we need to finalize the project timeline.', 'user': 'U01ABCD2EFG', 'ts': '1623948724.000200', 'team': 'T01HJKL3MNO', 'blocks': [{'type': 'rich_text', 'block_id': 'kS3', 'elements': [{'type': 'rich_text_section', 'elements': [{'type': 'text', 'text': 'Hey team, we need to finalize the project timeline.'}]}]}]}\"\n"
     ]
    }
   ],
   "source": [
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sarrah\\data_win\\Personal_Projects\\GSoC_24\\gsoc24\\Lib\\site-packages\\langchain_core\\vectorstores.py:379: UserWarning: Relevance scores must be between 0 and 1, got [(Document(page_content=\"U03HIJK5LMN said: I can schedule a meeting for tomorrow at 7 AM. at 1623948784.000400 in team T01HJKL3MNO. Full accompanying message was {'client_msg_id': 'd2c3d6e7-4176-4f58-b7c9-1d2e0b7e8d23', 'type': 'message', 'text': 'I can schedule a meeting for tomorrow at 7 AM.', 'user': 'U03HIJK5LMN', 'ts': '1623948784.000400', 'team': 'T01HJKL3MNO', 'blocks': [{'type': 'rich_text', 'block_id': '7kH', 'elements': [{'type': 'rich_text_section', 'elements': [{'type': 'text', 'text': 'I can schedule a meeting for tomorrow at 7 AM.'}]}]}]}\"), -12704.210399216032), (Document(page_content=\"U03HIJK5LMN said: I can schedule a meeting for tomorrow at 7 AM. at 1623948784.000400 in team T01HJKL3MNO. Full accompanying message was {'client_msg_id': 'd2c3d6e7-4176-4f58-b7c9-1d2e0b7e8d23', 'type': 'message', 'text': 'I can schedule a meeting for tomorrow at 7 AM.', 'user': 'U03HIJK5LMN', 'ts': '1623948784.000400', 'team': 'T01HJKL3MNO', 'blocks': [{'type': 'rich_text', 'block_id': '7kH', 'elements': [{'type': 'rich_text_section', 'elements': [{'type': 'text', 'text': 'I can schedule a meeting for tomorrow at 7 AM.'}]}]}]}\"), -12704.210399216032), (Document(page_content=\"U03HIJK5LMN said: I can schedule a meeting for tomorrow at 7 AM. at 1623948784.000400 in team T01HJKL3MNO. Full accompanying message was {'client_msg_id': 'd2c3d6e7-4176-4f58-b7c9-1d2e0b7e8d23', 'type': 'message', 'text': 'I can schedule a meeting for tomorrow at 7 AM.', 'user': 'U03HIJK5LMN', 'ts': '1623948784.000400', 'team': 'T01HJKL3MNO', 'blocks': [{'type': 'rich_text', 'block_id': '7kH', 'elements': [{'type': 'rich_text_section', 'elements': [{'type': 'text', 'text': 'I can schedule a meeting for tomorrow at 7 AM.'}]}]}]}\"), -12704.210399216032)]\n",
      "  warnings.warn(\n",
      "c:\\Users\\sarrah\\data_win\\Personal_Projects\\GSoC_24\\gsoc24\\Lib\\site-packages\\langchain_core\\vectorstores.py:391: UserWarning: No relevant docs were retrieved using the relevance score threshold 0.9\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to our schedule, the meeting to discuss the project timeline is set for 2 PM today. Please confirm if this timing works for you before we proceed with any further updates.\n"
     ]
    }
   ],
   "source": [
    "ans = chatter.ask(\"What time is the meeting scheduled to discuss the details of the project timeline?\")\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "chatter.clear()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gsoc24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
